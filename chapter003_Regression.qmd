---
title: "Regression Analysis"
output: html_document
editor_options: 
  chunk_output_type: console
---
   
```{r}
#| label: setup
#| include: false

library(tidyverse)
library(here)
library(ggpubr)
library(ggthemes)
library(broom)
library(qqplotr)
library(gt)
library(gtsummary)
library(SensorLab)
library(ggridges)
library(ggeffects)
library(modelr)
library(patchwork)
library(cardx)

```

::: {.content-visible when-profile="script"}

Regression analysis is a statistical method used to examine the relationship between one dependent variable and one or more independent variables. 
It aims to understand how the dependent variable changes when one or more independent variables change.

The core idea is to create a mathematical model that represents this relationship. 
The model is typically in the form of an equation that predicts the value of the dependent variable based on the values of the independent variables.

There are different types of regression analysis, such as linear regression (when the relationship between variables is linear) and nonlinear regression (when the relationship is not linear). 
The process involves finding the best-fitting line or curve that minimizes the differences between the predicted values from the model and the actual observed values.

:::

## Linear Regression

\begin{align}
y = \beta_0 + \beta_1 \cdot X \label{linreg}
\end{align}

```{r}
#| label: fig-lm-principle
#| out-width: 55%
#| fig-cap: The basic idea behind linear regression.
#| fig-pos: "H"

knitr::include_graphics(here::here("chapter003","029_lm_principle.png"))

```

::: {.content-visible when-profile="script"}

The basic idea behind linear regression is, to find the line of the form $Y = \beta_0 + \beta_1 \cdot X$ that best fits the datapoints.
In order to determine the best fit, a criterion to optimize for is needed.
This is where residuals come into play.

:::


### Residuals

::: {.r-stack}

:::{.fragment .fade-out}

```{r}
#| label: fig-lm-error
#| out-width: 75%
#| fig-cap: The calculation of residuals.
#| fig-pos: "H"

knitr::include_graphics(here::here("chapter003","030_lm_error.png"))

```

:::

:::{.fragment .fade-in-then-out}

The computation of the residuals is based on \eqref{rss} to the [residual sum of squares](#rss).

\begin{align}
RSS = \frac{1}{n} \sum_{i=1}^{n} (y_i - (\beta_1 x_i+\beta_0))^2 \label{rss}
\end{align}

:::

:::

### Gradient Descent [@Ruder2016]

```{r}
#| label: fig-grad-desc
#| out-width: 70%
#| fig-cap: An example for the gradient descent algorithm

knitr::include_graphics(here::here("chapter003","031_gradient_descent.png"))

```

::: {.content-visible when-profile="script"}
In linear regression, gradient descent is an iterative optimization process used to minimize the difference between predicted and actual values. 
It starts with initial coefficients and calculates the gradient of the cost function, representing the error. 
The coefficients are then updated in the opposite direction of the gradient, with the magnitude of the update controlled by a learning rate. 
This process is repeated until convergence, gradually refining the coefficients to improve the accuracy of the linear regression model.
:::


### Model Evaluation and Interpretation

::: {.r-stack}

:::{.fragment .fade-out}

```{r}
#| label: fig-lm
#| out-width: 75%
#| fig-cap: The linear regression between rounds per minute (rpm) of the lathing machine and the diameter of the drive shaft.
#| fig-pos: "H"

load(here("data","drive_shaft_rpm_dia.Rdata"))

drive_shaft_rpm_dia %>% 
  ggplot(aes(x = rpm, y = diameter))+
  geom_point()+
  geom_smooth(
    method = "lm"
    )+
  stat_regline_equation(
    aes(
      label =  
        paste(
          after_stat(eq.label),
          after_stat(rr.label), 
          after_stat(adj.rr.label),
          sep = "~~~~")
      ),
  )+
  labs(
    title = "linear regression line",
    x = "rpm in 1/min",
    y = "diameter in mm"
  )+
  theme_few()
  

lm_model = lm(diameter ~ rpm, data = drive_shaft_rpm_dia)

```

:::

:::{.fragment .fade-in-then-out}

::: {.content-visible when-profile="script"}

The [coefficient of determination](#r2) ($r^2$), is a statistical measure that assesses the proportion of the variance in the dependent variable that is explained by the independent variable(s) in a regression model. 
It ranges from $0$ to $1$, where $0$ indicates that the model does not explain any variability, and $1$ indicates that the model explains all the variability. 
In other words, $r^2$ provides insight into the goodness of fit of a regression model, indicating how well the model's predictions match the observed data.

:::

\begin{align}
r^2 = 1- \frac{RSS}{SSE} \label{r2}
\end{align}

:::

:::{.fragment .fade-in-then-out}

::: {.content-visible when-profile="script"}

The [adjusted coefficient of determination](#r2adj), is a modification of the regular $r^2$ in regression analysis. 
While $r^2$ assesses the proportion of variance explained by the independent variables, the $r^2_{adjusted}$ takes into account the [number of predictors ($k$)](#numpred) in the model, addressing potential issues with overfitting according to \eqref{r2adj}.

The $r^2_{adjusted}$ incorporates a penalty for adding unnecessary predictors that do not significantly contribute to explaining the variance in the dependent variable. 
This adjustment helps prevent an inflated $r^2$ when including more predictors, even if they don't improve the model significantly.

:::

```{r}
#| label: fig-r2vsr2adj
#| out-width: 75%
#| fig-cap: The influence of k (number of predictors) on $r^2$ and $r^2_{adjusted}$.
#| fig-pos: "H"

k <- seq(1,5)

rsq <- seq(0.5,0.99,0.01)

n <-  seq(10,60,10)
  
tmp <- expand_grid(
  rsq, k,n
) %>% 
  mutate(
    r2adj = 1-(1-rsq)*(k/(n-k+1))
  ) 
  

tmp %>% 
  ggplot(
    aes(x = rsq,
        y = r2adj,
        linetype = as.factor(k))
  ) +
  geom_hline(
    yintercept = 1,
    color = "gray"
    )+
  geom_line()+
  facet_wrap(
    ~n,
    labeller = label_both
  )+
  labs(
    x = bquote(r^2),
    y = bquote(r[adj]^2),
    linetype = "k (number of predictors)",
    title = bquote(r^2 ~ "and" ~ r[adj]^2 ~ "vs."~ k)
  )+
  theme_few()+
  theme(
    legend.position = "bottom"
  )

```


\begin{align}
r^2_{adjusted} = 1 - (1-r^2)\frac{n-1}{n-k-1} \label{r2adj}
\end{align}

:::

:::{.fragment .fade-in-then-out}

```{r}

summary(lm_model)

```
:::

:::{.fragment .fade-in-then-out}

::: {.content-visible when-profile="script"}
In linear regression modeling, the absence of a visible pattern in the residuals is desirable because it indicates that the model adequately captures the underlying relationship between the independent and dependent variables. 
Residuals are the differences between the observed and predicted values, and their randomness or lack of discernible pattern suggests that the model is effectively explaining the variance in the data. 
A visible pattern in residuals could indicate that the model fails to account for certain patterns or trends, suggesting potential shortcomings or misspecifications in the regression model. 
Detecting and addressing such patterns in residuals is crucial for ensuring the validity and reliability of the linear regression analysis.
:::

```{r}
#| label: fig-lm-resid-pattern
#| out-width: 75%
#| fig-cap: There should not be a visible pattern in the residuals.
#| fig-pos: "H"

lm_augmented <- lm_model %>% augment()

lm_augmented %>% 
  rowid_to_column(var = "sample_no") %>% 
  ggplot(aes(x = sample_no, y = .resid))+
  geom_point()+
  theme_few()

```
:::

:::{.fragment .fade-in-then-out}

```{r}
#| label: fig-lm-resid-qq
#| out-width: 75%
#| fig-cap: The resiuals should be normally distributed.
#| fig-pos: "H"

lm_augmented <- lm_model %>% augment()

lm_augmented %>% 
  ggplot(aes(sample = .resid))+
  stat_qq_band()+
  stat_qq_line()+
  stat_qq_point()+
  theme_few()

```

::: {.content-visible when-profile="script"}
In linear regression, the assumption of normally distributed residuals is essential for accurate statistical inference, parameter estimation using ordinary least squares, and constructing reliable confidence intervals. 
Normal residuals indicate that the model appropriately captures data variability and helps identify issues like heteroscedasticity. 
While departures from normality may not always invalidate results, adherence to this assumption enhances the model's robustness and reliability. 
If consistently violated, alternative modeling approaches or transformations may be considered.
:::

:::

:::

### Hypostesis testing in linear regression

:::{.fragment .fade-in-then-out}


[Null Hypothesis (H0)](#H0): $\beta_1 = 0$

[Alternative Hypothesis (Ha)](#Ha): $\beta_1 \neq 0$

```{r}
#| label: tbl-lm-t-test
#| tbl-cap: The significance of model parameters.

lm_model %>% 
  tidy() %>% 
  gt() %>% 
    fmt_number(
    decimals = 3
  ) 

```

::: {.content-visible when-profile="script"}
In linear regression, t testing of coefficients assesses whether individual regression coefficients significantly differ from zero, providing insights into the significance of each predictor's contribution to the model.
:::

```{r}
#| label: tbl-lm-f-test
#| tbl-cap: The significance of the model.

lm_model %>% 
  glance() %>% 
  select(
    -sigma,
    -logLik,
    -AIC,
    -BIC,
    -deviance
  ) %>% 
  gt() %>% 
  fmt_number(
    decimals = 3
  )

```

::: {.content-visible when-profile="script"}
In linear regression, the F-test assesses the overall significance of the regression model by comparing the fit of the model with predictors to a model without predictors, helping determine if the regression equation explains a significant proportion of the variance in the dependent variable.
:::


:::

## Multiple linear regression

::: {.r-stack}

::: {.fragment .fade-out}

```{r}
#| label: tbl-mlm-eda
#| tbl-cap: The data in a tabular overview including test for normal distribution.

load(file = here("data","drive_shaft_rpm_dia_feed.Rdata"))

drive_shaft_rpm_dia_feed %>% 
  tbl_summary(
    by = "site"
  ) %>% 
  add_p() %>% 
  add_overall()

```

::: {.content-visible when-profile="script"}
A short [exploratory data analysis](#eda) of the data for the multiple linear regression is given in @tbl-mlm-eda.
:::

:::

::: {.fragment .fade-in-then-out}

```{r}
#| label: fig-mlm-qq-eda
#| out-width: 75%
#| fig-cap: The graphical test for normal distribution (QQ-plot)
#| fig-pos: "H"

drive_shaft_rpm_dia_feed %>% 
  select(-site) %>% 
  pivot_longer(cols = everything()) %>% 
  ggplot(aes(sample = value))+
  # geom_histogram()+
  stat_qq_band()+
  stat_qq_line()+
  stat_qq_point()+
  facet_wrap(
    ~name,
    scales = "free"
  )+
  labs(
    title = "QQ-plot for the continous variables"
  )+
  theme_few()

```

::: {.content-visible when-profile="script"}

@fig-mlm-qq-eda shows the graphical test for normal distribution for the multiple linear regression.

:::

:::

::: {.fragment .fade-in-then-out}

```{r}
#| label: fig-mlm-hist
#| out-width: 75%
#| fig-cap: The distribution of the output and input parameters.
#| fig-pos: "H"

drive_shaft_rpm_dia_feed %>% 
  select(-site) %>% 
  pivot_longer(cols = everything()) %>% 
  ggplot(
    aes(x = value)
  )+
  geom_histogram()+
  facet_wrap(~name,scales = "free_x")+
  scale_y_continuous(
    expand = c(0,0,0.05,0)
  )+
  theme_few()
  
```

::: {.content-visible when-profile="script"}

In @fig-mlm-hist the distribution of the input data is shown in a histogram.

:::

:::

:::{.fragment .fade-in-then-out}

\begin{align}
Y \sim rpm + feed+ site \label{mlmmodel}
\end{align}

```{r}
#| label: tbl-mlm-mdl
#| tbl-cap: The output of the multiple linear regression modelling

mlm <- lm(diameter ~ rpm+feed+site ,data = drive_shaft_rpm_dia_feed)

mlm %>% 
  tbl_regression(
    add_estimate_to_reference_rows = T
  )

```

::: {.content-visible when-profile="script"}

\eqref{mlmmodel} shows the general model for the multiple linear regression model.
In this example, also the production site (`site A`, `site B` and `site C`) is included to test, if different production sites lead to differently produced drive shafts.
The results of the multiple regression are shown in @tbl-mlm-mdl.
Whilst the continuous variables appear to be significant ($p<\alpha = 0.05$), the production site does not play a significant rolefor the drive shaft diameter.
 
:::

:::

:::{.fragment .fade-in-then-out}

```{r}
#| label: fig-mlm-mdl
#| out-width: 75%
#| fig-cap: The model of the mulitple linear regression
#| fig-pos: "H"

drive_shaft_rpm_dia_feed %>% 
  pivot_longer(cols = c("rpm","feed")) %>% 
  ggplot(
    aes(
      x = value, y = diameter
    )
    )+
  geom_point()+
  geom_smooth(method = "lm")+
  facet_wrap(
    ~name,
    scales = "free_x"
  )+
  theme_few()

```

::: {.content-visible when-profile="script"}

In @fig-mlm-mdl the model is shown to ease the interpretation. 
With increasing `rpm` or `feed` also the drive shaft diameter increases.

:::

:::

:::{.fragment .fade-in-then-out}

```{r}
#| label: fig-mlm-resid-pattern
#| out-width: 75%
#| fig-cap: The check for pattern in the residuals
#| fig-pos: "H"

mlm %>% 
  augment() %>% 
  rowid_to_column(var = "sample_no") %>% 
  ggplot(
    aes(x = sample_no, 
        y = .resid)
  )+
  geom_point()+
  labs(
    title = "pattern in residuals"
  )+
  theme_few()


```
:::

:::{.fragment .fade-in-then-out}

```{r}
#| label: fig-mlm-resid-nd
#| out-width: 75%
#| fig-cap: The check for normal distribution in the residuals.
#| fig-pos: "H"

mlm %>% 
  augment() %>% 
  rowid_to_column(var = "sample_no") %>% 
  ggplot(
    aes(sample = .resid)
  )+
  stat_qq_band()+
  stat_qq_line()+
  stat_qq_point()+
  labs(
    title = "normal distributions of residuals"
  )+
  theme_few()


```

::: {.content-visible when-profile="script"}
In @fig-mlm-resid-nd the normal distribution of the residuals is confirmed, the model appears to be valid.
:::

:::

:::

{{< pagebreak >}}

## Logistic Regression

::: {.r-stack}

:::{.fragment .fade-in-then-out}

```{r}
#| label: fig-logreg-basic
#| out-width: 75%
#| fig-cap: The basic idea of logisitic regression.
#| fig-pos: "H"

knitr::include_graphics(here::here("chapter003","032_log_reg.png"))

```

::: {.content-visible when-profile="script"}

Logistic regression is a statistical method designed for binary classification problems (@fig-logreg-basic). 
It models the probability that an observation belongs to a particular class using the sigmoid (logistic) function \eqref{sigmoid}. The key steps include:

1. **Probability Modeling:**
   - Model predicts the probability of an instance belonging to a specific class.

2. **Linear Combination:**
   - Combines linearly weighted input features, representing the log-odds of the positive class.

3. **Sigmoid Function:**
   - Transforms the linear combination to ensure output is between 0 and 1.

4. **Decision Boundary:**
   - Threshold probability (usually $0.5$) determines class assignment.

5. **Maximum Likelihood Estimation:**
   - Parameters are estimated using maximum likelihood to maximize the likelihood of observed outcomes.

6. **Odds Ratio:**
   - Quantifies the impact of each predictor on the odds of the positive class.

Logistic regression is widely used for binary classification tasks in different domains, providing an interpretable way to model the relationship between predictors and a binary outcome.

:::

:::

:::{.fragment .fade-in-then-out}

\begin{align}
p = \frac{1}{1+e^{-(\beta_0 + \beta_1x)}} \label{sigmoid}
\end{align}

::: {.content-visible when-profile="slides"}

```{r}
#| out-width: 40%
#| fig-align: center
knitr::include_graphics(here("chapter003","but_why.jpg"))
```

:::

:::

:::{.fragment .fade-in-then-out}

The ordinary linear regression equation is shown in \eqref{linreg}.

::: {.content-visible when-profile="slides"}
$y = \beta_0 + \beta_1x$
:::

If for $y$ the probabilities $P$ are used they may be $>1$ or $<0$ which is not possible for $P$.

:::

:::{.fragment .fade-in-then-out}

To overcome this issue, the odds of $P = \frac{P}{1-P}$ are taken.

\begin{align}
\frac{P}{1-P} &= \beta_0 + \beta_1x \label{logreg01} \\
\frac{P}{1-P} &\in {0 \ldots + \infty} \nonumber
\end{align}

Restricted variables are not easy to model why \eqref{logreg01} is expanded to \eqref{logreg02}.

\begin{align}
\log\left( \frac{P}{1-P}\right) &= \beta_0 + \beta_1x \label{logreg02}
\end{align}

::: {.content-visible when-profile="script"}

Which then in turn gives \eqref{sigmoid}.

:::

:::

:::

{{< pagebreak >}}

### $\beta_0 = 1$ and $\beta_1 = 1$

```{r}
#| label: fig-sigmoid-params
#| out-width: 95%
#| fig-cap: The influence of different paramters for the sigmoid function
#| fig-pos: "H"

x <- seq(-5,5,0.1)
beta_0 <- 1
beta_1 <- 1

ref <- expand_grid(
  x = x,
  beta_1 = beta_1,
  beta_0 = beta_0
) |> 
  mutate(
    y_hat = sig_fun(x, beta_1 = beta_1,beta_0=beta_0),
    beta_0 = beta_0 |> as.factor(),
    beta_1 = beta_1 |> as.factor(),
  )

ref |> 
 ggplot(
    aes(
      x = x,
      y = y_hat,
    )
  )+
  geom_hline(yintercept = 0,color = "gray")+
  geom_vline(xintercept = 0,color = "gray")+
  geom_line()+
  labs(
    title = bquote(y == frac(1,1+e^-(beta[0]+beta[1]*x)) ~ ";" ~ beta[0] == 1 ~ ";" ~ beta[1] == 1),
    y = bquote(hat(y))
  )+
  scale_y_continuous(
    expand = c(0,0,0.05,0),
    breaks = seq(0,1,0.1)
  )+
  theme_tufte(
    base_size = 15
  )

```

::: {.content-visible when-profile="script"}

In order to better understand the influencing factors a small parametric study on $\beta_0$ and $\beta_1$ is given.
@fig-sigmoid-params the sigmoid function $p = \frac{1}{1+e^{-(\beta_0 + \beta_1x)}}$ with $\beta_0=1$ and $\beta_1 = 1$ is shown as a reference.
Please note that the *linear regression* ($\beta_0 + \beta_1x$) expands the usual *sigmoid* function which is given by 

$$f(x) = \frac{1}{1+e^{-x}}$$

to model it in the *intercept* and *gradient* kind of logic.

:::

{{< pagebreak >}}

### $\beta_0 = 1$ and $\beta_1 = 0 \ldots 5$

```{r}
#| label: fig-sigmoid-params02
#| out-width: 95%
#| fig-cap: The influence of different paramters for the sigmoid function
#| fig-pos: "H"
#| fig-height: 5

x <- seq(-5,5,0.1)
beta_0 <- 1
beta_1 <- seq(0,5)

dataset <- expand_grid(
  x = x,
  beta_1 = beta_1,
  beta_0 = beta_0
) |> 
  mutate(
    y_hat = sig_fun(x, beta_1 = beta_1,beta_0=beta_0),
    beta_0 = beta_0 |> as.factor(),
    beta_1 = beta_1 |> as.factor(),
  )

dataset |> 
 ggplot(
    aes(
      x = x,
      y = y_hat,
      linetype = beta_1
    )
  )+
  geom_hline(yintercept = 0,color = "gray")+
  geom_vline(xintercept = 0,color = "gray")+
  geom_line(
    data = ref,
    linewidth = 2,
    linetype = "solid",
    color = "gray",
    show.legend = FALSE
    )+
  geom_line()+
  labs(
    title = bquote(y == frac(1,1+e^-(beta[0]+beta[1]*x)) ~ ";" ~ beta[0] == 1 ~ ";" ~ beta[1] == list(0,...,5)),
    y = bquote(hat(y)),
    linetype = bquote(beta[1] ~":   ")
  )+
 scale_y_continuous(
    expand = c(0,0,0.05,0),
    breaks = seq(0,1,0.1)
  )+
  theme_tufte(
    base_size = 15
  )+
  theme(
    legend.position = "bottom"
  )+ 
  guides(linetype = guide_legend(nrow = 1))

```

::: {.content-visible when-profile="script"}

In the first case of the parametric study the *gradient* parameter is studied by varying it between $0\ldots5$ with $step_{size}=1$.
From @fig-sigmoid-params02 it can be seen, that the *linear regression gradient* parameters varies the characteristic *S*-like shape of the sigmoid function.
The higher $\beta_1$ is, the more pronounced the *S*-shape becomes.
The reference shape for $\beta_0 = 1$ and $\beta_1 = 1$ is shown in light gray in the figure.
An interesting effect is visible for a gradient of $\beta_1 = 0$: The function becomes a constant which only depends on the *intercept* (in this case $\beta_0=1$).

:::

{{< pagebreak >}}

### $\beta_0 = 1$ and $\beta_1 = -5 \ldots 0$

```{r}
#| label: fig-sigmoid-params03
#| out-width: 95%
#| fig-cap: The influence of different paramters for the sigmoid function
#| fig-pos: "H"
#| fig-height: 5

x <- seq(-5,5,0.1)
beta_0 <- 1
beta_1 <- seq(-5,0)

dataset <- expand_grid(
  x = x,
  beta_1 = beta_1,
  beta_0 = beta_0
) |> 
  mutate(
    y_hat = sig_fun(x, beta_1 = beta_1,beta_0=beta_0),
    beta_0 = beta_0 |> as.factor(),
    beta_1 = beta_1 |> as.factor(),
  )

dataset |> 
 ggplot(
    aes(
      x = x,
      y = y_hat,
      linetype = beta_1
    )
  )+
  geom_hline(yintercept = 0,color = "gray")+
  geom_vline(xintercept = 0,color = "gray")+
  geom_line(
    data = ref,
    linewidth = 2,
    linetype = "solid",
    color = "gray",
    show.legend = FALSE
    )+
  geom_line()+
  labs(
    title = bquote(y == frac(1,1+e^-(beta[0]+beta[1]*x)) ~ ";" ~ beta[0] == 1 ~ ";" ~ beta[1] == list(-5,...,0)),
    y = bquote(hat(y)),
    linetype = bquote(beta[1] ~":   ")
  )+
 scale_y_continuous(
    expand = c(0,0,0.05,0),
    breaks = seq(0,1,0.1)
  )+
  theme_tufte(
    base_size = 15
  )+
  theme(
    legend.position = "bottom"
  )+ 
  guides(linetype = guide_legend(nrow = 1))


```

::: {.content-visible when-profile="script"}

When the parameter study is expanded to negative values of $\beta_1$ ($\beta_1 = -5 \ldots 0$) the curve is mirrored and reverses its direction (see @fig-sigmoid-params03), which is also highlighted by the reference shape for $\beta_0 = 1$ and $\beta_1 = 1$ in light gray.
The general interpretation for the influence of this parameter is reversed by stays the same: the larger the deviation from $0$ is for $\beta_1$, the more pronounced the *S*-like shape becomes.

:::

{{< pagebreak >}}

### $\beta_0 = 0\ldots 5$ and $\beta_1 = 1$

```{r}
#| label: fig-sigmoid-params04
#| out-width: 95%
#| fig-cap: The influence of different paramters for the sigmoid function
#| fig-pos: "H"
#| fig-height: 5

x <- seq(-5,5,0.1)
beta_0 <- seq(0,5)
beta_1 <- 1

dataset <- expand_grid(
  x = x,
  beta_1 = beta_1,
  beta_0 = beta_0
) |> 
  mutate(
    y_hat = sig_fun(x, beta_1 = beta_1,beta_0=beta_0),
    beta_0 = beta_0 |> as.factor(),
    beta_1 = beta_1 |> as.factor(),
  )

dataset |> 
 ggplot(
    aes(
      x = x,
      y = y_hat,
      linetype = beta_0
    )
  )+
  geom_hline(yintercept = 0,color = "gray")+
  geom_vline(xintercept = 0,color = "gray")+
  geom_line(
    data = ref,
    linewidth = 2,
    linetype = "solid",
    color = "gray",
    show.legend = FALSE
    )+
  geom_line()+
  labs(
    title = bquote(y == frac(1,1+e^-(beta[0]+beta[1]*x)) ~ ";" ~ beta[0] == list(0,...,5) ~ ";" ~ beta[1] == 1),
    y = bquote(hat(y)),
    linetype = bquote(beta[0] ~":   ")
  )+
 scale_y_continuous(
    expand = c(0,0,0.05,0),
    breaks = seq(0,1,0.1)
  )+
  theme_tufte(
    base_size = 15
  )+
  theme(
    legend.position = "bottom"
  )+ 
  guides(linetype = guide_legend(nrow = 1))


```

::: {.content-visible when-profile="script"}

The second step is to vary the *intercept* ($\beta_1$) of the linear regression function that is "hidden" within the sigmoid function.
The reference function for $\beta_0 = 1$ and $\beta_1 = 1$ is again shown in light gray in the background in @fig-sigmoid-params04.
It can clearly be seen, that the *intercept* in a sigmoid-function setting can be used as a kind of offset.
Whilst the curve is exactly $0.5$ at $\beta_0 = 0$, this intersection can be adapted by modeling the intercept.
For $\beta_0 > 0$ the intersection point becomes $>0.5$.

:::

{{< pagebreak >}}

### $\beta_0 = -5 \ldots 0$ and $\beta_1 = 1$

```{r}
#| label: fig-sigmoid-params05
#| out-width: 95%
#| fig-cap: The influence of different paramters for the sigmoid function
#| fig-pos: "H"
#| fig-height: 5

x <- seq(-5,5,0.1)
beta_0 <- seq(-5,0)
beta_1 <- 1

dataset <- expand_grid(
  x = x,
  beta_1 = beta_1,
  beta_0 = beta_0
) |> 
  mutate(
    y_hat = sig_fun(x, beta_1 = beta_1,beta_0=beta_0),
    beta_0 = beta_0 |> as.factor(),
    beta_1 = beta_1 |> as.factor(),
  )

dataset |> 
 ggplot(
    aes(
      x = x,
      y = y_hat,
      linetype = beta_0
    )
  )+
  geom_hline(yintercept = 0,color = "gray")+
  geom_vline(xintercept = 0,color = "gray")+
  geom_line(
    data = ref,
    linewidth = 2,
    linetype = "solid",
    color = "gray",
    show.legend = FALSE
    )+
  geom_line()+
  labs(
    title = bquote(y == frac(1,1+e^-(beta[0]+beta[1]*x)) ~ ";" ~ beta[0] == list(-5,...,0) ~ ";" ~ beta[1] == 1),
    y = bquote(hat(y)),
    linetype = bquote(beta[0] ~":   ")
  )+
 scale_y_continuous(
    expand = c(0,0,0.05,0),
    breaks = seq(0,1,0.1)
  )+
  theme_tufte(
    base_size = 15
  )+
  theme(
    legend.position = "bottom"
  )+ 
  guides(linetype = guide_legend(nrow = 1))


```

::: {.content-visible when-profile="script"}

The reference function for $\beta_0 = 1$ and $\beta_1 = 1$ is again shown in light gray in the background in @fig-sigmoid-params05.
For an *intercept* $<0$ the intersection point with the `xaxis` then offsets the curve in the other direction compared with @fig-sigmoid-params04.
For $\beta_0 < 0$ the intersection point becomes $<0.5$.
In both cases the *S*-shape like characteristic of the sigmoid function is retained.

:::

### Maximum Likelihood Estimation (MLE)

:::{.r-stack}

:::{.fragment .fade-in-then-out}

::: {.content-visible when-profile="script"}
[Maximum Likelihood Estimation (MLE)](#MLE) is a statistical method used for estimating the parameters of a model [@StatQuest]. 
In this approach, the parameter values are chosen to maximize the likelihood function, which represents the probability of observing the given data under the assumed statistical model. 
The idea is to find the parameter values that make the observed data most probable.

:::

In contrast to the cost function for linear regression \eqref{mse}, $\hat{y_i}$ in logistic regression is a non-linear function \eqref{yhatlog}.

\begin{align}
\hat{y} = \frac{1}{1+e^{-z}} \label{yhatlog}
\end{align}

Which is why the [Maximum Likelihood Estimator](#MLE) is used.

Using the [MLE](#MLE) basically means, to try different models (with different model parameters) that maximize the likelihood of the parameters being true.
Because it is easier to look for minima (gradient descent), a loss function is formulated that can be used as a loss function.

:::

:::{.fragment .fade-in-then-out}

```{r}
#| label: fig-mle
#| out-width: 85%
#| fig-cap: The principle of MLE.
#| fig-pos: "H"
#| fig-height: 5

knitr::include_graphics(here("chapter003","033_mle.png"))

```

::: {.content-visible when-profile="script"}

\begin{align}
-\log L(\theta) = -\sum_{i=1}^{n} y \log(\sigma(\theta^Tx^i)) + (1-y)\log(1-\sigma(\theta^Tx^i)) \label{logresloss}
\end{align}


:::

:::

:::

### Modeling Production Data

:::{.r-stack}

:::{.fragment .fade-in-then-out}

```{r}
#| label: fig-logreg-data
#| out-width: 75%
#| fig-cap: The data for the logistic regression data.
#| fig-pos: "H"
#| fig-height: 5

load(file = here("data","drive_shaft_log_reg.Rdata"))

drive_shaft_log_reg %>% 
  ggplot(aes(x = feed, y = as.factor(pass_1_fail_0)))+
  geom_density_ridges(
    scale = 0.5,
    jittered_points = TRUE, 
    position = "raincloud",
    alpha = 0.7
  )+
  scale_y_discrete(
    labels = c("FAIL","PASS")
  )+
  labs(
    title = "Logistic regression data",
    x = "feed",
    y = ""
  )+
  theme_few(base_size = 15)

```
::: {.content-visible when-profile="script"}

In @fig-logreg-data the data for the production data.
The drive shafts have been rated between `PASS`and `FAIL` and the lathing machine feed has been recorded.
The question is now, at which feed the drive shafts start to FAIL.

:::

:::

:::{.fragment .fade-in-then-out}

```{r}
#| label: tbl-logreg-eda
#| tbl-cap: The overview of the logistic regression data.

drive_shaft_log_reg %>% 
  mutate(
    pass_1_fail_0 = as.factor(pass_1_fail_0)
  ) %>% 
  tbl_summary(
    include = !id
  )

```

::: {.content-visible when-profile="script"}

@tbl-logreg-eda shows an overview of the logistic regression data.
`PASS` and `FAIL` are fairly similar distributed.

:::

:::

:::{.fragment .fade-in-then-out}

```{r}
#| label: tbl-logreg-mdl
#| tbl-cap: The modeling of the logisitic regression data.

glm_model1 = glm(pass_1_fail_0 ~ feed , data = drive_shaft_log_reg, family = binomial(link="logit"))

glm_model1 %>% tbl_regression()

glm_coef <- glm_model1 %>% tidy() %>% pull(estimate) 

```

::: {.content-visible when-profile="script"}
The model coefficients are shown in @tbl-logreg-mdl.
Translated in equation \eqref{logregor} and \eqref{logrege} we can see, what has been computed.

:::

\begin{align}
\log(\frac{P}{1-P}) &= `r round(glm_coef[[1]],digits = 2)` + `r round(glm_coef[[2]],digits = 2)`x \label{logregor} \\
\frac{P}{1-P} &= e^{`r round(glm_coef[[1]],digits = 2)` + `r round(glm_coef[[2]],digits = 2)`x} \label{logrege}
\end{align}

Therefore the models explains what the odds $\frac{P}{1-P}$ are for a drive shaft to be `FAIL` or `PASS` for a given `feed`.

:::

:::{.fragment .fade-in-then-out}

```{r}
#| label: fig-logreg-mdl
#| out-width: 75%
#| fig-cap: The probability (odds) for a drive shaft being PASS or FAIL for a given feed
#| fig-pos: "H"
#| fig-height: 5

# newdat_pass_fail <- data.frame(
#   feed = seq(10,30,0.1)
# ) %>% 
#   nest() %>% 
#   mutate(
#     mean_pred = map(data,function(x) predict(glm_model1, type = "response",newdata = x,interval = "confidence"))
#   ) %>% 
#   unnest(
#     cols = c(data, mean_pred)
#   )

newdat_pass_fail <- ggpredict(
  model = glm_model1,
  terms = "feed [all]"
)

newdat_pass_fail %>% 
  ggplot(aes(x = x))+
  geom_hline(yintercept = 0.5,color = "gray")+
  geom_vline(xintercept = 20,color = "gray")+
  geom_line(aes(y = predicted,linetype = "mean"))+
  geom_line(aes(y = conf.low,linetype = "conf low"))+
  geom_line(aes(y = conf.high, linetype = "conf high"))+
  labs(
    title = "logistic regression model",
    y = "probability",
    linetype = "",
    x = "feed"
  )+
  scale_y_continuous(
    # expand = c(0,0,0,0),
    breaks = c(0,0.25,0.5,0.75,1)
    )+
  scale_linetype_manual(
    values = c("mean" = "solid",
               "conf low" = "dashed",
               "conf high" = "dashed")
  )+
  scale_x_continuous(expand = c(0,0,0,0))+
  theme_few(
    base_size = 15
  )+
  theme(
    legend.position = "bottom"
  )
  

pnt_pred <- ggpredict(
  model = glm_model1,
  terms = "feed "
) %>% 
  filter(
    x ==20
  )

```

::: {.content-visible when-profile="script"}

@fig-logreg-mdl shows the probability for a drive shaft `PASS` or `FAIL` for a given feed as well as the confidence interval of the odds ratio for any given feed.
For example the probability for `PASS` at a `feed` of `r pnt_pred$x` is $`r round(pnt_pred$predicted,digits = 2)*100` \%$ with a confidence interval of $`r round(pnt_pred$conf.low,digits = 2)*100`\%$ to $`r round(pnt_pred$conf.high,digits = 2)*100`\%$.

:::

:::

:::

##### residuals

```{r}
#| label: fig-logreg-qq
#| out-width: 85%
#| fig-cap: Are the residuals of the model normally distributed?
#| fig-pos: "H"
#| fig-height: 5

log_tidy <- glm_model1 |> broom::tidy()

log_glance <- glm_model1 |> broom::glance()

log_augment <- glm_model1 |> augment()

log_augment |> 
  mutate(
    pass_1_fail_0 = pass_1_fail_0 |> as.factor()
  ) |> 
  ggplot(
    aes(
      sample = .resid,
      # color = pass_1_fail_0
    )
  )+
  stat_qq_band()+
  stat_qq_line()+
  stat_qq_point()+
  facet_wrap(
    ~pass_1_fail_0,
    scales = "free",
    labeller = label_both
  )+
   theme_few(
    base_size = 15
  )+
  labs(
    title = "residuals distribution"
  )+
  theme(
    legend.position = "bottom"
  )

```



#### Mc Fadden $R^2$

::: {.content-visible when-profile="script"}

McFadden's $R^2$ is a measure used to evaluate the goodness of fit for logistic regression models and is calculated using \eqref{mcfadden}.

:::

\begin{align}
R^2 = 1- \frac{\log(L_{model})}{\log(L_{null})} \label{mcfadden} = `r pscl::pR2(glm_model1)[[4]]`
\end{align}

It compares the `model` to the `null`-model.
It is much smaller then the [coefficient of determination](#r2adj) with values ranging between $0.2 \ldots 0.4$ already indicating a good model fit in practice.

#### Confusion Matrix

:::{.r-stack}

:::{.fragment .fade-out}

```{r}
#| include: false 

con_mat_df <- drive_shaft_log_reg |> 
  select(-id) |> 
  mutate(
    pass_1_fail_0 = pass_1_fail_0 |> as_factor()
  )

con_mat_df <- con_mat_df |> 
  add_predictions(
    model = glm_model1,
    type = "response"
  ) |> 
  mutate(
    pred_class_05 = 
      case_when(
        pred>0.5~1,
        TRUE~0
      ) |> as_factor(),
    pred_class_03 = 
      case_when(
        pred>0.3~1,
        TRUE~0
      ) |> as_factor(),
    pred_class_07 = 
      case_when(
        pred>0.7~1,
        TRUE~0
      ) |> as_factor()
  )
  

cm03 <- caret::confusionMatrix(data=con_mat_df$pass_1_fail_0, con_mat_df$pred_class_03)
cm05 <- caret::confusionMatrix(data=con_mat_df$pass_1_fail_0, con_mat_df$pred_class_05)
cm07 <- caret::confusionMatrix(data=con_mat_df$pass_1_fail_0, con_mat_df$pred_class_07)


```

```{r}
#| label: fig-sngl-conmat
#| out-width: 50%
#| fig-cap: A confusion matrix

knitr::include_graphics(here("chapter003","conmat.png"))

```

:::

:::{.content-visible when-profile="script"}

A confusion matrix is a table used to evaluate the performance of a classification algorithm. 
It provides a detailed breakdown of the actual versus predicted classifications, enabling the calculation of various performance metrics. 
The matrix is particularly useful for binary and multiclass classification problems.

On the `x-axis` usually the *ground truth* is depicted whereas on the `y-axis` the predictions of the algorithm are shown.
From this several performance metrics can be calculated.

:::

:::{.fragment .fade-in-then-out}

- True Positive (**TP**): The number of positive instances correctly classified as positive.
- False Positive (**FP**): The number of negative instances incorrectly classified as positive (also known as Type I error).
- True Negative (**TN**): The number of negative instances correctly classified as negative.
- False Negative (**FN**): The number of positive instances incorrectly classified as negative (also known as Type II error).

:::

:::

##### Accuracy

$$\frac{TP + TN}{TP+FP+TN+FN}$$

:::{style="font-size: 85%;"}

Definition

:   The ratio of correctly predicted instances (both true positives and true negatives) to the total instances.

:::{.fragment .fade-in}

Interpretation

:   Accuracy measures the overall correctness of the model. It indicates the proportion of total predictions that were correct. While accuracy is useful, it can be misleading in cases of imbalanced datasets where one class is more frequent than the other.

:::

:::

##### Precision

$$\frac{TP}{TP+FP}$$

:::{style="font-size: 85%;"}

Definition 

:   The ratio of true positive instances to the total instances predicted as positive.

:::{.fragment .fade-in}

Interpretation

:   Precision, also known as positive predictive value, measures the accuracy of positive predictions. It is the proportion of correctly identified positive instances out of all instances predicted as positive. High precision indicates a low false positive rate.

:::

:::

##### Recall

$$\frac{TP}{TP+FN}$$

:::{style="font-size: 85%;"}

Definition
:   The ratio of true positive instances to the total actual positive instances.

:::{.fragment .fade-in}

Interpretation 

:   Recall measures the model’s ability to correctly identify all positive instances. It is the proportion of correctly identified positive instances out of all actual positive instances. High recall indicates a low false negative rate.

:::

:::

##### Specificity

$$\frac{TN}{TN+FP}$$

:::{style="font-size: 85%;"}

Definition  

:   The ratio of true negative instances to the total actual negative instances.

:::{.fragment .fade-in}

Interpretation 

:   Specificity measures the model’s ability to correctly identify negative instances. It is the proportion of correctly identified negative instances out of all actual negative instances. High specificity indicates a low false positive rate.

:::

:::

##### F1 Score

$$2\times\frac{Precision\times Recall}{Precision + Recall}$$

:::{style="font-size: 85%;"}

Definition 

:   The harmonic mean of precision and recall.

:::{.fragment .fade-in}

Interpretation 

:   The F1 Score combines precision and recall into a single metric. It provides a balance between the two, particularly useful when you need to take both false positives and false negatives into account. The F1 score is especially helpful when the class distribution is uneven or when you seek a balance between precision and recall.

:::

:::

##### Summary on metrics {.incremental}

- **Accuracy** is best for overall performance but can be misleading for imbalanced datasets.
- **Precision** is crucial when the cost of false positives is high.
- **Recall** is important when the cost of false negatives is high.
- **Specificity** complements recall, providing insight into the true negative rate.
- **F1 Score** offers a balanced measure, useful when both precision and recall are important.

#### Confusion Matrix in practice

```{r}
#| label: fig-glm-conmat05
#| out-width: 95%
#| fig-cap: Confusion matrices at different probability thresholds
#| fig-pos: "H"

p1 <- ggconmat(cm03)+
  labs(
    title = bquote(P == 0.3)
    )+
  ggplot2::theme_classic(
    base_size = 15
  )

p2 <- ggconmat(cm05)+
  labs(
    title = bquote(P == 0.5)
    )+
  ggplot2::theme_classic(
    base_size = 15
  )

p3 <- ggconmat(cm07)+
  labs(
    title = bquote(P == 0.7)
    )+
  ggplot2::theme_classic(
    base_size = 15
  )

p1+p2+p3+
  plot_layout(guides = "collect")+
  plot_annotation(
    title = "Confusion matrix for different thresholds",
    theme = theme(plot.title = element_text(size = 18)))&
  theme(legend.position = "bottom")

```

:::{.content-visible when-profile="script"}

@fig-glm-conmat05 shows three different confusion matrices at different probability threshold for the logistic regression model and the respective [True Positive](#TP), [False Positive](#FP), [True Negative](#TN) and [False Negative](#FN) rates.
On the `x-axis` the reference is depicted and the *true* classes, being $0$ for `FAIL` and $1$ for `PASS` parts.
The `y-axis` shows the prediction of the respective model with the classes again being $0$ for `FAIL` and $1$ for `PASS`.
The *probability threshold* $P = 0.3 \ldots 0.7$ is the classification threshold of the model.
The logistic regression model computes a *Probability* based on the *Predictor* variable (`feed`).
This threshold then classifies the product as `pass` or `fail`


:::

#### Accuracy, correct classification rate, proportion of correct predictions

```{r}

roc_mat <- drive_shaft_log_reg |> 
  select(-id) |> 
  mutate(
    pass_1_fail_0 = pass_1_fail_0 |> as_factor()
  ) |> 
  add_predictions(
    model = glm_model1,
    type = "response"
  ) |> 
  nest()

thresh <- seq(0.05,0.95,0.05)

roc_calc <- expand_grid(
  data = roc_mat$data,
  thresh
) |> 
  unnest(cols = c(data)) |> 
  mutate(
    pred = case_when(
      pred > thresh ~ 1,
      TRUE ~ 0
    ) |> 
      as_factor()
  ) |> 
  mutate(
    TP = case_when(
      (pass_1_fail_0 == pred)&(pass_1_fail_0 == 0) ~ 1,
      TRUE ~ 0
    ),
    TN = case_when(
      (pass_1_fail_0 == pred)&(pass_1_fail_0 == 1) ~ 1,
      TRUE ~ 0
    ),
    FP = case_when(
      (pass_1_fail_0 != pred)&(pred == 1) ~ 1,
      TRUE ~ 0
    ),
    FN = case_when(
      (pass_1_fail_0 != pred)&(pred == 0) ~ 1,
      TRUE ~ 0
    )
  )
  


roc_sngl_thresh <- roc_calc |> 
  group_by(thresh) |> 
  summarise(
    TP = sum(TP),
    TN = sum(TN),
    FP = sum(FP),
    FN = sum(FN),
    true_positive_rate = TP/(TP+FN),
    error_rate = (FP+FN)/(TP+TN+FN+FP),
    accuracy = (TP+TN)/(TP+FP+TN+FN),
    precision = TP/(TP+FP),
    recall = TP/(TP+FN),
    specificity = TN/(TN+FP),
    sensitivity = TP/(TP+FN),
    false_positive_rate = FP/(FP+TN),
    f1_score = 2*(precision*recall)/(precision+recall)
  )

roc_long <- roc_sngl_thresh |> 
  select(-TP,-TN,-FP,-FN) |> 
  pivot_longer(
    cols = !starts_with("thresh"),
    values_to = "metric_val",
    names_to = "metric_type") 



```


```{r}

roc_sngl_thresh |> 
  ggplot(
    aes(
      x = thresh,
      y = accuracy
    )
  )+
  geom_smooth(
    color = "gray",
    se = F
  )+
  geom_step()+
  geom_text(
    aes(
      label = TP+TN 
    ),
    nudge_x = 0.025,
    nudge_y = 0.025
  )+
  geom_text(
    aes(
      label = TP+FP+TN+FN 
    ),
    nudge_x = 0.025,
    nudge_y = -0.025
  )+
  scale_x_continuous(
    breaks = seq(0,1,0.1),
    labels = scales::percent
  )+
  scale_y_continuous(
    limits = c(0,1),
    breaks = seq(0,1,0.1),
    labels = scales::percent
  )+
  labs(
    title = bquote("accuracy: " ~ frac("correctly predicted","total instances")== frac(TP+TN,TP+FP+TN+FN)),
    x = "model response probability threshold"
  )+
  theme_classic(base_size = 15)
  

```

#### Precision

```{r}

roc_sngl_thresh |> 
  ggplot(
    aes(
      x = thresh,
      y = precision
    )
  )+
  geom_smooth(
    color = "gray",
    se = F
  )+
  geom_step()+
  geom_text(
    aes(
      label = TP 
    ),
    nudge_x = 0.025,
    nudge_y = 0.025
  )+
  geom_text(
    aes(
      label = TP+FP
    ),
    nudge_x = 0.025,
    nudge_y = -0.025
  )+
  scale_x_continuous(
    breaks = seq(0,1,0.1),
    labels = scales::percent
  )+
  scale_y_continuous(
    # limits = c(0,1),
    breaks = seq(0,1,0.1),
    labels = scales::percent
  )+
  labs(
    title = bquote("precision: " ~ frac("true positive","total positively predicted instances")== frac(TP,TP+FP)),
    x = "model response probability threshold"
  )+
  theme_classic(base_size = 15)
  

```

#### Recall, True positive rate, sensitivity, hit rate, detection rate

```{r}

roc_sngl_thresh |> 
  ggplot(
    aes(
      x = thresh,
      y = recall
    )
  )+
  geom_smooth(
    color = "gray",
    se = F
  )+
  geom_step()+
  geom_text(
    aes(
      label = TP 
    ),
    nudge_x = 0.025,
    nudge_y = 0.025
  )+
  geom_text(
    aes(
      label = TP+FP
    ),
    nudge_x = 0.025,
    nudge_y = -0.025
  )+
  scale_x_continuous(
    breaks = seq(0,1,0.1),
    labels = scales::percent
  )+
  scale_y_continuous(
    # limits = c(0,1),
    breaks = seq(0,1,0.1),
    labels = scales::percent
  )+
  labs(
    title = bquote("recall: " ~ frac("true positive","actual total positive predicted instances")== frac(TP,TP+FN)),
    x = "model response probability threshold"
  )+
  theme_classic(base_size = 15)
  

```

#### Specificity, true negative rate, selectivity, true negative fraction, 1 - false positive rate

```{r}

roc_sngl_thresh |> 
  ggplot(
    aes(
      x = thresh,
      y = specificity
    )
  )+
  geom_smooth(
    color = "gray",
    se = F
  )+
  geom_step()+
  geom_text(
    aes(
      label = TN 
    ),
    nudge_x = 0.025,
    nudge_y = 0.025
  )+
  geom_text(
    aes(
      label = TN+FP
    ),
    nudge_x = 0.025,
    nudge_y = -0.025
  )+
  scale_x_continuous(
    breaks = seq(0,1,0.1),
    labels = scales::percent
  )+
  scale_y_continuous(
    # limits = c(0,1),
    breaks = seq(0,1,0.1),
    labels = scales::percent
  )+
  labs(
    title = bquote("specificity: " ~ frac("true negative","actual negative instances")== frac(TN,TN+FP)),
    x = "model response probability threshold"
  )+
  theme_classic(base_size = 15)
  

```

#### F1 Score, harmonic mean of precision and recall

```{r}

roc_sngl_thresh |> 
  ggplot(
    aes(
      x = thresh,
      y = f1_score
    )
  )+
  geom_smooth(
    color = "gray",
    se = F
  )+
  geom_step()+
  # geom_text(
  #   aes(
  #     label = precision*recall |> round(digits = 3) 
  #   ),
  #   nudge_x = 0.025,
  #   nudge_y = 0.025
  # )+
  # geom_text(
  #   aes(
  #     label = (precision+recall) |> round(digits = 3)
  #   ),
  #   nudge_x = 0.025,
  #   nudge_y = -0.025
  # )+
  scale_x_continuous(
    breaks = seq(0,1,0.1),
    limits = c(0,1),
    labels = scales::percent
  )+
  scale_y_continuous(
    # limits = c(0,1),
    breaks = seq(0,1,0.1),
    labels = scales::percent
  )+
  labs(
    title = bquote("F1 Score: " ~ 2%*%frac(precision%*%recall,precition+recall)),
    x = "model response probability threshold"
  )+
  theme_classic(base_size = 15)
  

```

#### Receiver Operator Curve (ROC)

```{r}
#| fig-height: 7

roc_sngl_thresh |> 
  ggplot(
    aes(
      x = 1-specificity,
      y = sensitivity,
      color = thresh
    )
  )+
  geom_abline()+
  geom_smooth(
    color = "gray",
    se = F
  )+
  geom_step(
    linewidth = 1.5
  )+
  scale_x_continuous(
    limits = c(0,1),
    expand = c(0,0,0,0),
    breaks = seq(0,1,0.1),
    labels = scales::percent
  )+
  scale_y_continuous(
    limits = c(0,1),
    expand = c(0,0,0,0),
    breaks = seq(0,1,0.1),
    labels = scales::percent
  )+
  scale_color_viridis_c(
    option = "H"
  )+
  theme_classic(
    base_size = 15
  )+
  labs(
    title = "ROC",
    x = "1-specificity, false positive rate",
    y = "sensitvity, true positive rate",
    color = "model response probability threshold"
  )+
  coord_equal()

```

#### METRICSSS!!!!!

```{r}
#| fig-height: 7


roc_long |> 
  ggplot(
    aes(
      x = thresh,
      y = metric_val,
      color = metric_type
    )
  )+
  geom_path(
    linewidth = 2
  )+
  scale_color_brewer(
    palette = "Set1"
  )+
  scale_x_continuous(
    breaks = seq(0,1,0.1),
    expand = c(0,0,0,0),
    labels = scales::percent
  )+
  scale_y_continuous(
    breaks = seq(0,1,0.1),
    expand = c(0,0,0,0),
    labels = scales::percent
  )+
  labs(
    title = "We can make it even more confusing!",
    x = "model response probability threshold"
  )+
  theme_classic(base_size = 15)+
  theme(
    legend.position = "bottom"
  )

```


::: {.content-visible when-profile="script"}

# Chose a statistical Test

**One Proportion Test:**
Used for binary categorical data to compare a sample proportion to a known population proportion.

**Chi-Square Goodness of Fit Test:**
Assesses whether observed categorical data frequencies match expected frequencies.

**One Sample T-Test:**
Compares a sample mean to a known or hypothesized population mean for continuous data, assuming a normal distribution.

**One Sample Wilcoxon Test:**
Non-parametric test for continuous data or ordinal data to compare a sample's median to a known population median.

**Cochran's Q Test:**
Evaluates proportions in three or more related categorical groups, often with repeated measures.

**Chi-Square Test of Independence:**
Determines if two categorical variables are associated.

**Pearson Correlation:**
Measures linear relationships between two continuous variables, assuming normal distribution.

**Spearman Correlation:**
Non-parametric alternative for non-linear or non-normally distributed data.

**T-Test for Independent Samples:**
Compares means of two independent groups for continuous data, assuming normal distribution.

**Welch T-Test for Independent Samples:**
Used when variances between two independent groups are unequal.

**Mann-Whitney U Test:**
Non-parametric alternative for comparing two independent groups with non-normally distributed data.

**T-Test for Paired Samples:**
Compares means of two related groups or repeated measures, assuming normal distribution.

**Wilcoxon Signed Rank Test:**
Non-parametric alternative for paired data or non-normally distributed data.

**One-Way ANOVA:**
Compares means of three or more independent groups for continuous data, assuming normal distribution.

**Welch ANOVA:**
Utilized when variances between groups being compared are unequal.

**Kruskal-Wallis Test:**
Non-parametric alternative for comparing three or more independent groups with non-normally distributed data.

**Repeated Measures ANOVA:**
For continuous data with multiple measurements within the same subjects over time.

**Friedman Test:**
Non-parametric alternative for analyzing non-normally distributed data with repeated measures.

```{r}
#| label: fig-chs-tst
#| out-width: 95%
#| fig-cap: Roadmap to choosse the right test
knitr::include_graphics(here::here("chapter003","012_StatisticalTests.pdf"))
```

:::

