---
title: "Basic Concepts"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup
#| include: false

library(tidyverse)
library(patchwork)
library(gghalves)
library(ggridges)
library(here)
library(ggthemes)
library(gt)
library(gtsummary)

```

```{r}
#| label: basics-001
#| fig-width: 10
#| fig-cap: The necessary statistical ingredients.
knitr::include_graphics(here::here("chapter000","000_basics_root.png"))
```

::: {.content-visible when-profile="script"}

Statistics is a fundamental field that plays a crucial role in various disciplines, from science and economics to social sciences and beyond. It's the science of collecting, organizing, analyzing, interpreting, and presenting data. In this introductory overview, we'll explore some key concepts and ideas that form the foundation of statistics:

1. **Data:** At the heart of statistics is data. Data can be anything from numbers and measurements to observations and information collected from experiments, surveys, or observations. In statistical analysis, we work with two main types of data: quantitative (numerical) and qualitative (categorical).

2. **Descriptive Statistics:** Descriptive statistics involve methods for summarizing and organizing data. These methods help us understand the basic characteristics of data, such as measures of central tendency (mean, median, mode) and measures of variability (range, variance, standard deviation).

3. **Inferential Statistics:** Inferential statistics is about making predictions, inferences, or decisions about a population based on a sample of data. This involves hypothesis testing, confidence intervals, and regression analysis, among other techniques.

4. **Probability:** Probability theory is the foundation of statistics. It deals with uncertainty and randomness. We use probability to describe the likelihood of events occurring in various situations, which is essential for making statistical inferences.

5. **Sampling:** In most cases, it's impractical to collect data from an entire population. Instead, we often work with samples, which are smaller subsets of the population. The process of selecting and analyzing samples is a critical aspect of statistical analysis.

6. **Variables:** Variables are characteristics or attributes that can vary from one individual or item to another. They can be categorized as dependent (response) or independent (predictor) variables, depending on their role in a statistical analysis.

7. **Distributions:** A probability distribution describes the possible values of a variable and their associated probabilities. Common distributions include the normal distribution, binomial distribution, and Poisson distribution, among others.

8. **Statistical Software:** In the modern era, statistical analysis is often conducted using specialized software packages like R, Python (with libraries like NumPy and Pandas), SPSS, or Excel. These tools facilitate data manipulation, visualization, and complex statistical calculations.

9. **Ethics and Bias:** It's essential to consider ethical principles in statistical analysis, including issues related to data privacy, confidentiality, and the potential for bias in data collection and interpretation.

10. **Real-World Applications:** Statistics has a wide range of applications, from medical research to marketing, finance, and social sciences. It helps us make informed decisions and draw meaningful insights from data in various fields.

:::

## Probability

### Overview

Probability theory is a fundamental concept in the field of statistics, serving as the foundation upon which many statistical methods and models are built. 

### What is Probability?

Probability is a mathematical concept that quantifies the uncertainty or randomness of events. 
It provides a way to measure the likelihood of different outcomes occurring in a given situation. 
In essence, probability is a numerical representation of our uncertainty.

### Basic Probability Terminology {.smaller}

- **Experiment**: An experiment is any process or procedure that results in an outcome. 
For example, rolling a fair six-sided die is an experiment.

- **Outcome**: An outcome is a possible result of an experiment. 
When rolling a die, the outcomes are the numbers 1 through 6.

- **Sample Space (S)**: The sample space is the set of all possible outcomes of an experiment. 
For a fair six-sided die, the sample space is $\{1, 2, 3, 4, 5, 6\}$.

- **Event (E)**: An event is a specific subset of the sample space. 
It represents a particular set of outcomes that we are interested in. 
For instance, "rolling an even number" is an event for a six-sided die, which includes outcomes $\{2, 4, 6\}$.

### Probability Notation

In probability theory, we use notation to represent various concepts:

- **P(E)**: Probability of event E occurring.
- **P(A and B)**: Probability of both events A and B occurring.
- **P(A or B)**: Probability of either event A or event B occurring.
- **P(E')**: Probability of the complement of event E, which is the probability of E not occurring.

### The Fundamental Principles of Probability {.smaller}

There are two fundamental principles of probability:

- **The Addition Rule**: It states that the probability of either event A or event B occurring is given by the sum of their individual probabilities, provided that the events are mutually exclusive (i.e., they cannot both occur simultaneously).

\begin{align}
P(A \; or \; B) = P(A) + P(B)
\end{align}

- **The Multiplication Rule**: It states that the probability of both event A and event B occurring is the product of their individual probabilities, provided that the events are independent (i.e., the occurrence of one event does not affect the occurrence of the other).

\begin{align}
P(A \; and\;B) = P(A) * P(B)
\end{align}

### Example: Rolling a Fair Six-Sided Die

::: {.content-visible when-profile="script"}

Consider rolling a fair six-sided die. 

- Sample Space (S): $\{1, 2, 3, 4, 5, 6\}$ (@fig-prob)
- Event A: Rolling an even number = $\{2, 4, 6\}$ (@fig-prob)
- Event B: Rolling a number greater than $3 = \{4, 5, 6\}$ (@fig-prob)
:::

```{r}
#| label: fig-prob
#| out-width: 75%
#| fig-cap: This example's sample space, as well as event A and event B.
knitr::include_graphics(here::here("chapter000","010_Probability.png"))
```

::: {.content-visible when-profile="script"}

Calculation of some probabilities:

- Probability of Event A (P(A)): $P(A) = \frac{\text{Number of outcomes in A}}{\text{Total number of outcomes in S}} = \frac{3}{6} = \frac{1}{2}$

- Probability of Event B (P(B)): $P(B) = \frac{3}{6} = \frac{1}{2}$

- Probability of both A and B (P(A and B)): 4 and 6 satisfy both A and B, $P(A\;and\;B) = \frac{2}{6} = \frac{1}{3}$

This example demonstrates the fundamental principles of probability and how they can be applied to real-world situations.

In the subsequent chapters of this course, more advanced concepts in probability theory will be explored, including conditional probability, random variables, probability distributions, and statistical inference. 

### Population Definition

In the field of statistics, a population refers to the entire group or collection of individuals, objects, or events under study. 
For example, when conducting a survey to examine the average income of households in a country, the population encompasses all the households within that country.

### Random Sampling

To study a population, statisticians often employ random sampling techniques as it may not be feasible or practical to gather data from every member of the population. 
Probability principles come into play during the selection of a random sample, ensuring that the sampling process adheres to well-defined rules to represent the population adequately.

### Sampling Distribution

Once a random sample is acquired, probability theory becomes instrumental in analyzing and characterizing various sample statistics, such as the sample mean and variance. 
The sampling distribution serves as a probability distribution, encompassing all possible values of sample statistics attainable through random sampling.

### Inferential Statistics

Probability plays a pivotal role in drawing conclusions about the population based on the data obtained from the sample. 
Statistical methodologies, including hypothesis testing and constructing confidence intervals, rely on probability theory to assess the likelihood of specific outcomes and quantify the associated uncertainty.

### Estimation

Probability is a key element in parameter estimation. 
For instance, when estimating population parameters like the mean or variance based on a sample, statisticians employ probability distributions such as the t-distribution or chi-squared distribution to create confidence intervals and determine margins of error.

### Hypothesis Testing

In hypothesis testing, probability is employed to ascertain whether observed differences or associations in sample data hold statistical significance. Probability calculations aid in evaluating whether the observed results are likely to be a product of random chance or if they genuinely reflect characteristics of the population.

### Generalization

The primary objective of statistical analysis is to generalize findings from the sample to the entire population. Probability allows for quantifying the likelihood that the characteristics observed in the sample accurately represent the entire population, while also considering the inherent uncertainty associated with the sampling process.

:::

### Probability in action - The Galton Board
::: {.content-visible when-profile="script"}

A Galton board, also known as a bean machine or a quincunx, is a mechanical device that demonstrates the principles of probability and the normal distribution. 
It was invented by Sir Francis Galton[^6] in the late 19th century. The Galton board consists of a vertical board with a series of pegs or nails arranged in triangular or hexagonal patterns.

A Galton board, also known as a bean machine or a quincunx, is a mechanical device that demonstrates the principles of probability and the normal distribution. It was invented by Sir Francis Galton in the late 19th century. The Galton board consists of a vertical board with a series of pegs or nails arranged in triangular or hexagonal patterns.

1. **Initial Release**: At the top of the Galton board, a ball or particle is released. 
This ball can take one of two paths at each peg, either to the left or to the right. 
The decision at each peg is determined by chance, such as the flip of a coin or the roll of a die. 
This represents a random event.

2. **Multiple Trials**: As the ball progresses downward, it encounters several pegs, each of which randomly directs it either left or right. 
The ball continues to bounce off pegs until it reaches the bottom.

3. **Accumulation**: Over multiple trials or runs of the Galton board, you will notice that the balls accumulate in a pattern at the bottom. 
This pattern forms a bell-shaped curve, which is the hallmark of a normal distribution.

4. **Normal Distribution**: The accumulation of balls at the bottom resembles the shape of a normal distribution curve. 
This means that the majority of balls will tend to accumulate in the center, forming the peak of the curve, while fewer balls will accumulate at the extreme left and right sides.

The Galton board is a visual representation of the [central limit theorem](#clt), a fundamental concept in probability theory. 
It demonstrates how random events, when repeated many times, tend to follow a normal distribution. 
This distribution is commonly observed in various natural phenomena and is essential in statistical analysis.

[^6]: Sir Francis Galton (1822-1911): Influential English scientist, notable for his contributions to statistics and genetics.

:::

```{r}
#| label: fig-plinko
#| out-width: 75%
#| fig-cap: A Galton board in action.

knitr::include_graphics(here::here("chapter000","011_Plinko.png"))

```


#### Statistics and Probabbility

::: {.content-visible when-profile="slides"}

What is the probability for a ball to land in one of the bins?

:::

::: {.content-visible when-profile="script"}

The Galton board is a nice example how statistics emerge from probability.

:::

##### Define the problem

- The board has $n$ rows of pegs (columns)
- Each ball has an equal probability of moving left or right (assuming no bias)
- The number of rightward moves determines the final position in the bins

::: {.content-visible when-profile="script"}


##### Step 2: Binomial Probability Distribution

Each ball independently moves right ($R$) or left ($L$) with a probability of $p=0.5$.

The number of rightwards moves follows a binomial distribution.

\begin{align}
P(k) = \binom{n}{k} p^k (1 - p)^{n - k} 
\end{align}

$n$
: total number of columns (or pegs encountered)

$k$
: number of rightward moves

$\binom{n}{k}$
: biomial coefficient, given by $\binom{n}{k} = \frac{n!}{k!(n-k)!}$

with $p = 0.5$ this simplifies to

\begin{align}
P(k) = \binom{n}{k} ( \frac{1}{2})^n
\end{align}

##### Step 3: Position Mapping

The final position of a ball in a bin corresponds to the number of rightwards moves $k$. 
If the bins are indexed from $0$ to $n$ (where $k=0$ means all left moves and $k=n$ means all right moves) the probability of landing in bin $k$ is:

\begin{align}
P(k) = \frac{n!}{k!(n-k)!}(\frac{1}{2})^n
\end{align}

:::

::: {.content-visible when-profile="slides"}

##### Formulate the Problem

- ball posistion depends on the number of rightwards moves $k$
- bins are indexed from $0$ to $n$ ($k = 0 \rightarrow \text{all left}; k = n \rightarrow \text{all right}$)

for $n = 4$ bins there are $4! = 24$ ways for the ball to choose

What is the probability for a ball to "choose" a bin?


##### The probability for a specific sequence

Suppose we have $n = 6$ bins. 
What is the probability for this sequence:

$$RRLLRL$$

::: {.fragment .fade-in}
$$P(RRLLRL) = \frac{1}{2}\cdot\frac{1}{2}\cdot\frac{1}{2}\cdot\frac{1}{2}\cdot\frac{1}{2}\cdot\frac{1}{2} = \left( \frac{1}{2} \right)^n$$ 
:::

::: {.fragment .fade-in}

Is it different for another sequence?

:::

##### Bins and Sequence

Is it sure, that every ball that follows a specific sequence lands in it's own bin?

::: {.fragment .fade-in}

Of course not.

:::

::: {.fragment .fade-in}

How is that probability calculated?

:::

##### Generalizing to $k$ right moves

Calculate the probability of exactly $k = 3$ right moves in $n = 6$

::: {.fragment .fade-in}

How many possibilities are there in total?

:::

::: {.fragment .fade-in}

$6! = 6 \times 5\times 4 \times 3 \times 2 \times 1 = 720$

:::

::: {.fragment .fade-in}

The factorial takes ALL sequences into account, but does it matter?

:::

::: {.fragment .fade-in}

We do not care for the order in which the turns are taken!

How do we correct for that?

:::

##### Correction for order


We correct for $k! = 3 \times 2 \times 1 = 6$, the number of ways to arrange the $k$ chosen elements among themselves.

$$\frac{n!}{k!} = \frac{720}{6} = 120$$

::: {.fragment .fade-in}

Are we finished?

:::

##### Correction for Unselected Elements

$(n-k)$ elements are not *chosen*, so we divide by another factorial, to correct fo the *NOT* chosen ones.

$$(n-k)! = (6-3)! = 3! = 6$$

##### Binomial Coefficient

$$\frac{n!}{k!(n-k)!} = \frac{720}{6\times6} = 20$$

This is called the *Binomial Coefficient* and it is written

$$\binom{n}{k}$$

So, the number of ways to choose $3$ elements out of $6$ is $20$.



##### Probability??

Now we know how many ways are there to choose, but in order to cacluclate a probability we still need to multiply this with the probability for **each** sequence

$$P(k) = \binom{n}{k}\cdot{\frac{1}{2}}^n$$

##### Detailed Calculation

::: {.r-stack}

::: {.fragment .fade-out}

::: {style="font-size: 70%;"}

| $k$ |  $n!$ |  $k!$ |       $(n-k)!$      | $\binom{n}{k} = \binom{6}{k}$ | $P(k) = \binom{6}{k}\cdot{\frac{1}{2}}^{n=6}$ |
|:---:|:-----:|:-----:|:-------------------:|:-----------------------------:|:---------------------------------------------:|
| $0$ | $720$ |  $1$  | $(6-0)! = 6! = 720$ | $\frac{720}{1 \cdot 720} = 1$ |    $P(0) = 1 \cdot \frac{1}{64} = 0.015624$   |
| $1$ |       |       |                     |                               |                                               |
| $2$ |       |       |                     |                               |                                               |
| $3$ |       |       |                     |                               |                                               |
| $4$ |       |       |                     |                               |                                               |
| $5$ |       |       |                     |                               |                                               |
| $6$ |       |       |                     |                               |                                               |

:::

:::

::: {.fragment .fade-in-then-out}

::: {style="font-size: 70%;"}

| $k$ |  $n!$ |  $k!$ |       $(n-k)!$      | $\binom{n}{k} = \binom{6}{k}$ | $P(k) = \binom{6}{k}\cdot{\frac{1}{2}}^{n=6}$ |
|:---:|:-----:|:-----:|:-------------------:|:-----------------------------:|:---------------------------------------------:|
| $0$ | $720$ |  $1$  | $(6-0)! = 6! = 720$ | $\frac{720}{1 \cdot 720} = 1$ |    $P(0) = 1 \cdot \frac{1}{64} = 0.015624$   |
| $1$ | $720$ |  $1$  | $(6-1)! = 5! = 120$ | $\frac{720}{1 \cdot 120} = 6$ |    $P(1) = 6 \cdot \frac{1}{64} = 0.093750$   |
| $2$ | $720$ |  $2$  |  $(6-2)! = 4! = 24$ | $\frac{720}{2 \cdot 24} = 15$ |   $P(2) = 15 \cdot \frac{1}{64} = 0.234375$   |
| $3$ | $720$ |  $6$  |  $(6-3)! = 3! = 6$  |  $\frac{720}{6 \cdot 6} = 20$ |   $P(3) = 20 \cdot \frac{1}{64} = 0.312500$   |
| $4$ | $720$ |  $24$ |  $(6-4)! = 2! = 2$  | $\frac{720}{24 \cdot 2} = 15$ |   $P(2) = 15 \cdot \frac{1}{64} = 0.234375$   |
| $5$ | $720$ | $120$ |  $(6-5)! = 1! = 1$  | $\frac{720}{120 \cdot 1} = 6$ |    $P(5) = 6 \cdot \frac{1}{64} = 0.093750$   |
| $6$ | $720$ | $720$ |  $(6-6)! = 0! = 1$  | $\frac{720}{720 \cdot 1} = 1$ |    $P(6) = 1 \cdot \frac{1}{64} = 0.015624$   |

:::

:::

:::

##### Graphical representation

::: {.r-stack}

::: {.fragment .fade-out}

```{r}
#| fig-width: 15
#| fig-height: 8


galton_dat <- data.frame(
  bin_nr = seq(0,6),
  n = 6
) |> 
  rowwise() |> 
  mutate(
    binom_coef = pracma::nchoosek(n,bin_nr),
    Prob = binom_coef*(0.5^n)
  )

galton_dat |> 
  ggplot(
    aes(
      x = bin_nr,
      y = Prob
      )
  )+
  geom_col()+
  scale_y_continuous(
    expand = c(0,0,0.05,0)
  )+
  theme_minimal(
    base_size = 15
  )

```

:::

::: {.fragment .fade-in}

```{r}
#| fig-width: 15
#| fig-height: 8


galton_dat <- data.frame(
  bin_nr = seq(0,1000),
  n = 1000
) |> 
  rowwise() |> 
  mutate(
    binom_coef = pracma::nchoosek(n,bin_nr),
    Prob = binom_coef*(0.5^n)
  )

galton_dat |> 
  ggplot(
    aes(
      x = bin_nr,
      y = Prob
      )
  )+
  geom_col()+
  scale_y_continuous(
    expand = c(0,0,0.05,0)
  )+
  theme_minimal(
    base_size = 15
  )

```

:::

:::

:::

## Population 

```{r}
#| label: population-001
#| out-width: 75%
#| fig-cap: An example for a population.
knitr::include_graphics(here::here("chapter000","002_Population.png"))
```

::: {.content-visible when-profile="script"}

In statistics, a population is the complete set of individuals, items, or data points that are the subject of a study.
Understanding populations and how to work with them is fundamental in statistical analysis, as it forms the basis for making meaningful inferences and drawing conclusions about the broader group being studied.
It is the complete collection of all elements that share a common characteristic or feature and is of interest to the researcher. 
The population can vary widely depending on the research question or problem at hand.
A populations *true mean* is depicted with [$\mu_0$](#truemean-gloss) and the variance is depicted with [$\sigma_0^2$](#truevariance-gloss).

:::

## Sample

```{r}
#| label: sample-001
#| out-width: 75%
#| fig-cap: A sample drawn from the population.
knitr::include_graphics(here::here("chapter000","003_Sample.png"))
```

::: {.content-visible when-profile="script"}

The key principles behind a sample include its role as a manageable subset of data, which can be chosen randomly or purposefully. 
Ideally, it should be representative, reflecting the characteristics and diversity of the larger population. 
Statistical techniques are then applied to this sample to make inferences, estimate population parameters, or test hypotheses. 
The size of the sample matters, as a larger sample often leads to more precise estimates, but it should be determined based on research goals and available resources. 
Various sampling methods, such as random sampling, stratified sampling, or cluster sampling, can be employed depending on the research objectives and population characteristics.
A samples *true mean* is depicted with [$\bar{x}$](#mean-gloss) and the variance is depicted with [$sd$](#sd-gloss).
:::

## Descriptive Statistics

::: {.content-visible when-profile="script"}

Descriptive Statistics:
Descriptive statistics are used to summarize and describe the main features of a data set. 
They provide a way to organize, present, and analyze data in a meaningful and concise manner. 
Descriptive statistics do not involve making inferences or drawing conclusions beyond the data that is being analyzed.
Instead, they aim to provide a clear and accurate representation of the data set. 
Some common techniques and measures used in descriptive statistics include:

1. Measures of Central Tendency:
   - Mean (average)
   - Median (middle value)
   - Mode (most frequent value)

2. Measures of Variability or Dispersion:
   - Range (difference between the maximum and minimum values)
   - Variance (average of the squared differences from the mean)
   - Standard Deviation (square root of the variance)

3. Frequency Distributions:
   - Histograms
   - Density plots
   - Frequency tables
   - Bar charts 

4. Summary Statistics:
   - Percentiles
   - Quantiles

:::

### Histogram

```{r}
#| label: fig-plot-sample-001
#| out-width: 75%
#| fig-cap: An example for descriptive statistics (histogramm)

df <- industRial::syringe_diameter %>% 
  tidyr::pivot_longer(cols = starts_with("Sample"),
               names_to = "sample",
               values_to = "diameter")

df %>% 
  ggplot(aes(x = diameter))+
  geom_histogram(color = "white")+
  scale_y_continuous(
    expand = c(0,0,0.05,0)
  )+
  labs(
    x = "diameter in mm",
    y = "count",
    title = "A histogram of the syringe data."
  )+
  scale_x_continuous(
    expand = c(0,0,0,0)
  )+
  ggthemes::theme_few()
  

```

::: {.content-visible when-profile="script"}

An example for descriptive statistics is shown in @fig-plot-sample-001 as a histogram.
It shows data from a company that produces pharmaceutical syringes, taken from @Ram2021.
During the production of those syringes, the so called *barrel diameter* is a critical parameter to the function of the syringe and therefore of special interest for the [Quality Control](#QC).

A histogram as shown in @fig-plot-sample-001 shows the data of `r nrow(df)` measurements during the [QC](#QC).
On the `x-axis` the *barrel diameter* is shown, while the count of each *binned* diameter is shown on the `y-axis`.
The binning and of data is a crucial parameter for such a plot, because it already changes the appearance and width of the bars.
Binning is a trade-off between visibility and readability.

:::

::: {.content-visible when-profile="slides"}

### Bad histograms

```{r}
#| label: fig-plot-sample-002
#| out-width: 75%
#| fig-cap: A bad example for histograms.


plt1 <- df %>% 
  ggplot(aes(x = diameter))+
  geom_histogram(color = "white",bins = 1)+
  scale_y_continuous(
    expand = c(0,0,0.05,0)
  )+
  labs(
    x = "diameter in mm",
    y = "count",
    title = "A histogram of the syringe data\nwith only one bin."
  )+
  scale_x_continuous(
    expand = c(0,0,0,0)
  )+
  ggthemes::theme_few()

plt2 <- df %>% 
  ggplot(aes(x = diameter))+
  geom_histogram(color = "white",bins = 150)+
  scale_y_continuous(
    expand = c(0,0,0.05,0)
  )+
  labs(
    x = "diameter in mm",
    y = "count",
    title = "A histogram of the syringe data\nwith too many bins."
  )+
  scale_x_continuous(
    expand = c(0,0,0,0)
  )+
  ggthemes::theme_few()

plt1+plt2  

```

:::

### Density plot

```{r}
#| label: fig-plot-density
#| out-width: 75%
#| fig-cap: An example for a density plot for the syringe data (barrel diameter).

df %>% 
  ggplot(aes(x = diameter, after_stat(scaled)))+
  geom_density(fill="grey")+
  scale_y_continuous(
    expand = c(0,0,0.05,0)
  )+
  labs(
    x = "diameter in mm",
    y = "density",
    title = "A density plot of the syringe data."
  )+
  scale_x_continuous(
    expand = c(0,0,0,0)
  )+
  ggthemes::theme_few()
  

```

::: {.content-visible when-profile="script"}

Density plots are another way of displaying the statistical distribution of an underlying dataset.
The biggest strength of those plots is, that no binning is necessary in order to show the data.
The limitation of this kind of plot is the interpretability.
An example of a density plot for the syringe data is shown in @fig-plot-density.
On the `x-axis` the syringe barrel diameter is shown (as in a histogram).
The `y-axis` in contrast does not display the count of a binned category, but rather the [Probability Density Function](#PDf) for the specific diameter.
The grey area under the density curve depicts the probability of a syringe diameter to appear in the data.
The complete area under the curve equals to $1$ meaning that a certain diameter is sure to appear in the data.

:::

### Boxplot

```{r}
#| label: fig-plot-sample-003
#| out-width: 75%
#| fig-cap: A boxplot of the same syringe data combined with the according histogram.
#| fig-pos: "H"


df %>% 
  ggplot(aes(x = diameter))+
  geom_histogram(color = "white",alpha = 0.4)+
  geom_boxplot(aes(y = 7),width = 4,lwd = 1,outlier.size = 1)+
  scale_y_continuous(
    expand = c(0,0,0.05,0)
  )+
  labs(
    x = "diameter in mm",
    y = "count",
    title = "A histogram of the syringe data\nwith an overlayed boxplot."
  )+
  scale_x_continuous(
    expand = c(0,0,0,0)
  )+
  ggthemes::theme_few()
  

```

::: {.content-visible when-profile="script"}

It is very common to include and inspect measures of central tendency in the graphical depiction of data.
A `boxplot`, also known as a box-and-whisker plot, is a very common way of doing this.
A `boxplot` is a graphical representation of a dataset's distribution. 
It displays the following key statistics:

1. Median (middle value).
2. Quartiles ($25^{th}$ and $75^{th}$ percentiles), forming a box.
3. Minimum and maximum values (whiskers).
4. Outliers (data points significantly different from the rest).

The syringe data in boxplot form is shown in @fig-plot-sample-003 as an overlay of the histogram plot before.
Boxplots are useful for quickly understanding the central tendency, spread, and presence of outliers in a dataset, making them a valuable tool in data analysis and visualization.

:::


### Average, Standard deviation and Range

```{r}
#| label: fig-plot-sample-031
#| out-width: 75%
#| fig-cap: A histogram of the syringe data with mean, standard deviation and range.


df %>% 
  ggplot(aes(x = diameter))+
  geom_histogram(color = "white",alpha = 0.4)+
  geom_point(aes(x = mean(diameter),y = 7),size = 5,shape = 8)+
  geom_errorbarh(aes(xmin = (mean(diameter)-sd(diameter)),
                     xmax = (mean(diameter)+sd(diameter)),
                     y = 7,linetype = "standard deviation"))+
  geom_errorbarh(aes(xmin = (min(diameter)),
                     xmax = (max(diameter)),
                     y = 3,linetype = "range"))+
  scale_linetype_manual(values = c("standard deviation" = "solid",
                                   "range" = "dashed"))+
  scale_y_continuous(
    expand = c(0,0,0.05,0)
  )+
  labs(
    x = "diameter in mm",
    y = "count",
    title = "A histogram of the syringe data\nwith mean, standard deviation and range",
    linetype = "type of spread"
  )+
  scale_x_continuous(
    expand = c(0,0,0,0)
  )+
  ggthemes::theme_few()+
  theme(legend.position = "bottom")
  

```

::: {.content-visible when-profile="script"}

Very popular measures of central tendency include the *average* (mean) and the *standard deviation* (variance) of a dataset.
The computed mean from an actual dataset is depicted with [$\bar{x}$](#mean-gloss) and calculated via \eqref{mean}.

\begin{align}
\bar{x} = \frac{1}{n}\sum_{i=1}^{n} x_i \label{mean}
\end{align}

With [$n$]{#n-gloss} being the number of datapoints and [$x_i$](#n-gloss) being the datapoints.
The *mean* is therefore the sum of all datapoints divided by the total number $n$ of all datapoints.
It is not to be confused with the true mean [$\mu_0$](#truemean-gloss) of a population.

The computed *standard deviation* from an actual dataset is depicted with [$sd$]{#sd-gloss} and calculated via \eqref{sd}.

\begin{align}
sd = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})^2} \label{sd}
\end{align}

The *standard deviation* can therefore be explained as the square root of the sum of all differences of each individual datapoints to the mean of a dataset divided by the number of datapoints.
It is not to be confused with the true variance [$\sigma_0^2$](#truevariance-gloss) of a population.
The variance of a dataset can be calculatd via \eqref{var}.

\begin{align}
\sigma = sd^2 \label{var}
\end{align}

The *range* from an actual dataset is depicted with [$r$](#range-gloss) and calculated via \eqref{range}.

\begin{align}
r = \max(x_i) - \min(x_i) \label{range}
\end{align}

The *range* can therefore be interpreted as the range from minimum to maximum in a dataset.

:::

## Visualizing Groups {#sec-vis-grps}

### Boxplots

```{r}
#| label: fig-groups-boxplot
#| out-width: 75%
#| fig-cap: Boxplots of the syringe data with the samples as groups.

df %>% 
  ggplot(aes(x = diameter,y = sample))+
  geom_boxplot()+
  labs(
    x = "diameter in mm",
    title = "Boxplots of the syringe data with samples as groups"
  )+
  scale_x_continuous(
    expand = c(0,0,0,0)
  )+
  ggthemes::theme_few()
  

```

::: {.content-visible when-profile="script"}

The methods described above are especially useful when it comes to visualizing groups in data.
The data is discretized and the information density is increased.
As with every discretization comes also a loss of information.
It is therefore strongly advised to choose the right tool for the job.

If the underlying distribution of the data is unknown, a good start to visualize groups within data is usually a boxplot as shown in @fig-groups-boxplot.
The syringe data from @Ram2021 contains six different groups, one for every sample drawn. 
Each sample consists of 25 observations in total.
On the `x-axis` the *diameter* in mm is shown, the `y-axis` depicts the sample number.
The `boxplots` are then drawn as described above (median, $25^{th}$ and $75^{th}$ percentile box, $5^{th}$ and $95^{th}$ whisker).
The $25^{th}$ and $75^{th}$ percentile box is also known as the [Interquartile Range](#iqr)

:::

### Mean and standard deviation plots

```{r}
#| label: fig-groups-mean-sd
#| out-width: 75%
#| fig-cap: Mean and standard deviation plots of the groups in the dataset.

df_grouped <- df %>% 
  group_by(sample) %>% 
  summarise(
    mean_d = mean(diameter),
    sd_d = sd(diameter)
  )

df_grouped %>% 
  ggplot(aes(x = mean_d,y = sample))+
  geom_point(shape = 8,size = 5)+
  geom_errorbarh(aes(xmin = mean_d - sd_d,xmax = mean_d +sd_d,y=sample),
                 height = 0.35)+
  labs(
    x = "diameter in mm",
    title = "Mean and standard deviation plot of the groups"
  )+
  scale_x_continuous(
    expand = c(0.05,0,0.05,0)
  )+
  ggthemes::theme_few()
  

```

::: {.content-visible when-profile="script"}

If the data follows a normal distribution, showing the mean and standard deviation for each group is also very common.
For the syringe dataset, this is shown in @fig-groups-mean-sd.
The plot follows the same logic as for the boxplots (`x-axis-data`, `y-axis-data`), but the data itself shows the mean with a $\times$-symbol, as the length of the horizontal errorbars accords to $\bar{x} \pm sd(x)$.

:::


### Half-half plots

```{r}
#| label: fig-groups-halves
#| out-width: 70%
#| fig-cap: Half-half plots that incooperate different types of plots

df %>% 
  ggplot(aes(y = diameter,x = sample))+
  geom_half_violin()+
  geom_half_point()+
  labs(
    x = "diameter in mm",
    title = "Half-Half plots including violin plots (PDF)\nand jittered raw-data"
  )+
  scale_x_discrete(
    expand = c(0,0,0,0)
  )+
  scale_y_continuous(
    expand = c(0.05,0,0.05,0)
  )+
  ggthemes::theme_few(base_size = 11)

```

::: {.content-visible when-profile="script"}

Boxplots and mean-and-standard-deviation plots sometimes hide some details within the data, that may be of interest or simply important.
Half-half plots, as shown in shown in @fig-groups-halves, incorporate different plot mechanisms.
The left half shows a violin plot, which outlines the underlying distribution of the data using the PDF.
This is very similar to a density plot.
The right half shows the original data points and give the user a visible clue about the sample size in the data size.
Note that the `y`-position of the points is jittered to counter *overplotting*.
Details can be found in @Tiedemann2022.

:::

### Ridgeline plots

```{r}
#| label: fig-groups-ridge
#| out-width: 75%
#| fig-cap: Ridgeline plots for distributions within groups.

df %>% 
  ggplot(aes(x = diameter,y = sample))+
  geom_density_ridges()+
  labs(
    x = "diameter in mm",
    title = "Ridgeline plots showing\nthe PDF for every group."
  )+
  scale_x_continuous(
    expand = c(0.05,0,0.05,0)
  )+
  scale_y_discrete(
    expand = c(0,0,0,0)
  )+
  ggthemes::theme_few()

```

::: {.content-visible when-profile="script"}

@fig-groups-ridge shows so called *ridgeline* plots as explained in @Wilke2022.
They are in essence density plots that use the `y-axis` to differentiate between the groups.
On the `x-axis` the density of the underlying dataset is shown.
More info on the creation of these plots and graphics is available in @Wickham2016 as well as @RGraphGallery.

:::

## The drive shaft exercise

### Introduction

```{r}
#| label: fig-drive-shaft-spec
#| out-width: 75%
#| fig-cap: The drive shaft specification.

knitr::include_graphics(here::here("chapter000","005_DriveShaft.png"))
```

::: {.content-visible when-profile="script"}

A drive shaft is a mechanical component used in various vehicles and machinery to transmit rotational power or torque from an engine or motor to the wheels or other driven components. 
It serves as a linkage between the power source and the driven part, allowing the transfer of energy to propel the vehicle or operate the machinery.

1. Material Selection: Quality steel or aluminum alloys are chosen based on the specific application and requirements.

2. Cutting and Machining: The selected material is cut and machined to achieve the desired shape and size. 
Precision machining is crucial for balance and performance.

3. Welding or Assembly: Multiple sections may be welded or assembled to achieve the required length. 
Proper welding techniques are used to maintain structural integrity.

4. Balancing: Balancing is critical to minimize vibrations and ensure smooth operation. 
Counterweights are added or mass distribution is adjusted.

5. Surface Treatment: Drive shafts are often coated or treated for corrosion resistance and durability. 
Common treatments include painting, plating, or applying protective coatings.

6. Quality Control: Rigorous quality control measures are employed to meet specific standards and tolerances. 
This includes dimensional checks, material testing, and defect inspections.

7. Packaging and Distribution: Once quality control is passed, drive shafts are packaged and prepared for distribution to manufacturers of vehicles or machinery.

The end diameter of a drive shaft is primarily determined by its torque capacity, length, and material selection. 
It needs to be designed to handle the maximum torque while maintaining structural integrity and flexibility as required by the specific application.
For efficient load transfer, there are ball bearings mounted on the end diameter.
Ball bearings at the end diameter of a drive shaft support its rotation, reducing friction. 
They handle axial and radial loads, need lubrication for longevity, and may include seals for protection. 
Proper alignment and maintenance are crucial for their performance and customization is possible to match specific requirements.

The end diameter of the drive shaft shall be $\varnothing 12\pm0.1mm$ (see @fig-drive-shaft-spec).
This example will haunt us the rest of this lecture.

:::

### Visualizing all the Data

```{r}
#| label: fig-ds-dist
#| layout-ncol: 2
#| out-width: 75%
#| fig-cap: The raw data of the measured drive shaft diameter.
#| fig-subcap: 
#| - The drive shaft data shown in a histogram.
#| - The drive shaft data shown in a density plot.

load(here("data","drive_shaft_data.Rdata"))

drive_shaft %>% 
  ggplot(aes(x = diameter))+
  geom_histogram()+
  geom_boxplot(aes(y = 30),width = 10)+
  labs(
    title = "A histogram of the drive shaft data"
  )+
  scale_x_continuous(expand = c(0,0,0,0))+
  scale_y_continuous(expand = c(0,0,0.05,0))+
  theme_few()
  
drive_shaft %>% 
  ggplot(aes(x = diameter))+
  geom_density()+
  labs(
    title = "A density plot of the drive shaft data"
  )+
  scale_x_continuous(expand = c(0,0,0,0))+
  scale_y_continuous(expand = c(0,0,0.05,0))+
  theme_few()
```

::: {.content-visible when-profile="script"}

First, some descriptive statistics of $N=500$ produced drive shafts are shown in @tbl-ds-sum ($\bar{x}(sd), median(IQR)$).
This first table does not tell us an awful lot about the sample, apart from the classic statistical measures of central tendency and spread.

```{r}
#| label: tbl-ds-sum
#| tbl-cap: The summary table of the drive shaft data


load(here("data","drive_shaft_data.Rdata"))

# drive_shaft <- drive_shaft %>% 
#   filter(group == "group01")

drive_shaft %>% 
  tbl_summary(
    # by = group,
    include = diameter,
      statistic = list(
      all_continuous() ~ "{mean} ({sd}), {median} ({IQR})"
      # all_categorical() ~ "{n} / {N} ({p}%)"
    ),
  ) %>% 
    modify_header(label ~ "**Variable**") %>% 
  as_gt() 
  # tab_footnote(footnote = "mean (sd), median (IQR)")
  

```

In @fig-ds-dist the data and the distribution thereof is visualized using different modalities.
The complete `drive shaft data` is shown as a histogram (@fig-ds-dist-1) and as a density plot (@fig-ds-dist-2).
A single boxplot is plotted over the histogram data in @fig-ds-dist-1, providing a link to @tbl-ds-sum (median and [IQR](#iqr)).
One important conclusion may be draw from those plots already:
There may be more than one dataset hidden inside the data. 
We will explore this possibility further.

:::

### Visualizing groups within the data

```{r}
#| label: fig-ds-grps
#| layout-ncol: 2
#| out-width: 75%
#| fig-cap: The raw data of the measured drive shaft diameter.
#| fig-subcap: 
#| - The groups visualized as boxplots (including the specification)
#| - The groups visualized as ridgeline plots

load(here("data","drive_shaft_data.Rdata"))

drive_shaft %>% 
  ggplot(aes(y = diameter,x = group))+
  geom_rect(xmin = -Inf, xmax = Inf, ymin = 11.9, ymax = 12.1,alpha = 0.1,fill = "azure2")+
  geom_jitter(alpha = 0.25,width = 0.2)+
  geom_boxplot(alpha = 0.5)+
  # geom_half_boxplot(alpha = 0.5)+
  # geom_half_violin(side = "r",alpha=0.5)+
  geom_hline(
    data = data.frame(spec = 12.0),
    aes(yintercept = spec,linetype = "nominal")
    )+
  geom_hline(
    data = data.frame(lo = 11.9),
    aes(yintercept = lo,linetype = "lower limit")
    )+
  geom_hline(
    data = data.frame(hi = 12.1),
    aes(yintercept = hi,linetype = "upper limit")
    )+
  scale_linetype_manual(
    values = c("nominal" = "solid", "lower limit" = "dashed", "upper limit" = "dashed")
      )+
  labs(
    title = "Drive shaft measurements and specification",
    x = "",
    y = "diameter in mm",
    linetype = ""
  )+
  theme_few()+
  theme(legend.position = "bottom")

drive_shaft %>% 
  ggplot(aes(x = diameter, y = group))+
  geom_density_ridges()+
  geom_vline(aes(xintercept = 12,linetype = "nominal"),key_glyph = draw_key_path)+
  geom_vline(aes(xintercept = 11.9,linetype = "lower limit"),key_glyph = draw_key_path)+
  geom_vline(aes(xintercept = 12.1,linetype = "upper limit"),key_glyph = draw_key_path)+
  scale_x_continuous(expand = c(0,0,0,0))+
  scale_y_discrete(expand = c(0,0,0.05,0))+
  labs(
    title = "Drive shaft measurement and specification",
    y = "",
    linetype = ""
      )+
  scale_linetype_manual(
    values = c("nominal" = "solid", "lower limit" = "dashed", "upper limit" = "dashed")
      )+
  theme_few()+
  theme(legend.position = "bottom")
  

```

::: {.content-visible when-profile="script"}

Fortunately for us, the groups that may be hidden within the data are marked in the orginal dataset and denoted as `group0x`.
Unfortunately for us, it is not known (purely from the data) how these groups come about.
Because we did get the dataset from a colleague, we need to investigate the *creation* of the dataset even further.
This is an important point, for without knowledge about the history of the data, it is *impossible* or at least *unadvisable* to make valid statements about the data.
We will go on with a table of summary statistics, see @tbl-ds-sum-grps.
Surprisingly, there are five groups hidden within the data, something we would no be able to spot from the raw data alone.


```{r}
#| label: tbl-ds-sum-grps
#| tbl-cap: The group summary table of the drive shaft data


load(here("data","drive_shaft_data.Rdata"))

drive_shaft <- drive_shaft %>%
  pivot_wider(names_from = "group",values_from = "diameter")

drive_shaft %>% 
  tbl_summary(
    # by = group,
    include = starts_with("group"),
      statistic = list(
      all_continuous() ~ "{mean} ({sd}), {median} ({IQR})"
      # all_categorical() ~ "{n} / {N} ({p}%)"
    ),
  ) %>% 
    modify_header(label ~ "**Variable**") %>% 
  as_gt() 
  # tab_footnote(footnote = "mean (sd), median (IQR)")
  

```

Again, the table is good to have, but not as engagingi for ourself and our co-workers to look at.
In order to make the data more approachable, we will use some techniques shown in @sec-vis-grps.

First in @fig-ds-grps-1 the raw data points are shown as points with overlayed boxplots.
On the `x-axis` the groups are depicted, while the [Parameter of Interest](#poi) (in this case the *end diameter* of the drive shaft) is shown on the `y-axis`.
Because we are interested how the manufactured drive shafts behave [with respect to](#wrt) the specification limit, the `nominal` value as well as the `uppper` and the `lower` specification limit is also shown in the plot as horizontal lines.

In @fig-ds-grps-2 the data is shown as ridgeline density plots.
On the `x-axis` the diameter is depiected, while the `y-axis` shows two types of data.
First, the groups $1\ldots5$ are shown. 
For the individual groups, the probability is depicted as a line, therefore indicating which values are most probable in the given group.
Again, because we are interested how the manufactured drive shafts behave .w.r.t the specification limit, the `nominal` value as well as the `uppper` and the `lower` specification limit is also shown in the plot as vertical lines.

:::


